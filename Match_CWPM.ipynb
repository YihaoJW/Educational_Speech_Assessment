{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sequence_matching\n",
    "import pandas as pd\n",
    "import glob\n",
    "import nltk\n",
    "from typing import List, Dict, Tuple, Iterator, Iterable, Set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jackwang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jackwang/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Download punkt and pos_tag\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Create dict for reference text\n",
    "passage_dict = sequence_matching.create_passage_dict(\"../DataFolder/Original_CSV/yrs12_passages.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Read all *.plist files under Result and create a generator that iter over all files\n",
    "file_list = glob.glob('Result/*.plist')\n",
    "file_generator = map(sequence_matching.read_plist, file_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# a function that input a list of tuple with(word info, status) and return a c_w_p_m\n",
    "# return 0 if the list is empty\n",
    "def get_c_w_p_m(common: List[Tuple[Dict, str]]) -> Tuple[float, int, float]:\n",
    "    list_correct_word = [x for x, c in common if c == 'M']\n",
    "    if len(list_correct_word) == 0:\n",
    "        return 0., 0, 0.\n",
    "    else:\n",
    "        list_correct_word.sort(key=lambda x: x['tTime'])\n",
    "        time_diff = (list_correct_word[-1]['tTime'] + list_correct_word[-1]['tDuration'] - list_correct_word[0]['tTime']) / 60\n",
    "        total_word = len(list_correct_word)\n",
    "        c_w_p_m = total_word / time_diff\n",
    "    return time_diff, total_word, c_w_p_m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# a function that input a list of all files path\n",
    "# first read the data and filename using read_plist\n",
    "# parse the filename to get passage id then get related passage using passage id\n",
    "# match the reference text with the student text using lcs\n",
    "# if the KeyError is raised, it goes to the next file\n",
    "# save the result to a csv file\n",
    "# first column is the file name, second column is the is time_diff third is total word last is  c_w_p_m\n",
    "# return the dataframe\n",
    "def get_c_w_p_m_for_all_files(file_list: Iterable[str], passage_dict: Dict[str, str], prob: float = 0.1, stemmer: nltk.stem.api = None, path : str = 'c_w_p_m.csv') -> Tuple[pd.DataFrame, Set[str]]:\n",
    "    result = []\n",
    "    errors_list = set()\n",
    "    for file in file_list:\n",
    "        try:\n",
    "            data, filename = sequence_matching.read_plist(file)\n",
    "            cleaned_filename = filename.split('_')\n",
    "            cleaned_filename[3] = str(int(cleaned_filename[3]) % 100000)\n",
    "            cleaned_filename = '_'.join(cleaned_filename)\n",
    "            tokenized_text = sequence_matching.read_and_tokenize_file(cleaned_filename, passage_dict)\n",
    "            common = sequence_matching.lcss(tokenized_text, data, prob = prob, stemmer = stemmer)\n",
    "            time_diff, total_word, c_w_p_m = get_c_w_p_m(common)\n",
    "            result.append([cleaned_filename, time_diff, total_word, c_w_p_m])\n",
    "        except KeyError as e:\n",
    "            errors_list.add(e.args[0])\n",
    "            continue\n",
    "    df = pd.DataFrame(result, columns=['file', 'time_diff', 'total_word', 'c_w_p_m'])\n",
    "    df.to_csv(path, index=False)\n",
    "    return df, errors_list\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df, err1 = get_c_w_p_m_for_all_files(file_list, passage_dict, prob = 0.1, stemmer = nltk.stem.LancasterStemmer(), path = 'c_w_p_m_stemmed.csv')\n",
    "df2, err2 = get_c_w_p_m_for_all_files(file_list, passage_dict, prob = 0.1, stemmer = None, path = 'c_w_p_m.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# data, fname= sequence_matching.read_plist('Result/student_1_passage_24000_56df1ab8df17d.wav.plist')\n",
    "# tokenized_text = sequence_matching.read_and_tokenize_file(fname, passage_dict)\n",
    "# result_tuple = sequence_matching.lcss(tokenized_text, data, prob = 0.1, stemmer = nltk.stem.LancasterStemmer())\n",
    "# list_correct_word = [x for x, c in result_tuple if c == 'M']\n",
    "# len(list_correct_word)\n",
    "# get_c_w_p_m(result_tuple)\n",
    "# list_correct_word\n",
    "# len(tokenized_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(err1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'1-2-3'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'-'.join(['1', '2', '3'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}