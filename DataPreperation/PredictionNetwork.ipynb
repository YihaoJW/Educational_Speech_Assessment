{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:01:52.851679Z",
     "start_time": "2023-11-08T19:01:49.703880Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow import Tensor\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Callable, List, Tuple, Union, Optional, Dict, Any, Sequence, Iterable, TypeVar\n",
    "from DataPipe import DataPipeFactory\n",
    "from util_function import inform_pooling, Get_Gradient"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Disable all GPUS\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "visible_devices = tf.config.get_visible_devices()\n",
    "for device in visible_devices:\n",
    "    assert device.device_type != 'GPU'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:01:52.853407Z",
     "start_time": "2023-11-08T19:01:52.850352Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#####\n",
    "#####6824149711"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:01:52.855545Z",
     "start_time": "2023-11-08T19:01:52.852692Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "ds = DataPipeFactory('../DataFolder/Tensorflow_DataRecord/Student_Answer_Record.tfrecord',\n",
    "                     '../DataFolder/Siri_Related/Siri_Reference_Sample',\n",
    "                     '../DataFolder/Siri_Related/Siri_Dense_Index', cache='../DataFolder/cache/datapipe/cached')\n",
    "# dsp = ds.get_batch_data(10)\n",
    "# it = iter(dsp)\n",
    "raw = ds.get_raw_data()\n",
    "A = tf.Variable(-1.)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:01:53.324139Z",
     "start_time": "2023-11-08T19:01:52.856106Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "student_len = []\n",
    "reference_len = []\n",
    "# try to get the stastic of the length of the student and reference\n",
    "for i,d in tqdm(enumerate(raw)):\n",
    "    student_len.append(tf.shape(d['stu_mfcc'])[0])\n",
    "    reference_len.append(tf.shape(d['ref_mfcc'])[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:01:59.236512Z",
     "start_time": "2023-11-08T19:01:53.325334Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "student_len[1].numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T19:01:59.237031Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stu_np = list(map(lambda x: x.numpy(), student_len))\n",
    "ref_np = list(map(lambda x: x.numpy(), reference_len))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:01:59.239412Z",
     "start_time": "2023-11-08T19:01:59.238305Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "stu_np.sort(reverse=True)\n",
    "ref_np.sort(reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T00:57:27.714404Z",
     "start_time": "2023-10-26T00:57:27.699886Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "stu_np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T00:59:01.883921Z",
     "start_time": "2023-10-26T00:59:01.876868Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#ds.pre_save()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T18:51:10.656092Z",
     "start_time": "2023-06-09T18:51:10.653222Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "iter(ds.get_batch_data(10, interleave=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T01:44:17.329044Z",
     "start_time": "2023-10-20T01:44:17.221855Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "for i,d in tqdm(enumerate(ds.get_batch_data(10, interleave=False, deterministic=False))):\n",
    "    if i % 50 == 0:\n",
    "        print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T01:44:34.099521Z",
     "start_time": "2023-10-20T01:44:21.147893Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i,d in tqdm(enumerate(ds.get_batch_data(10))):\n",
    "    batch = 10\n",
    "    value = tf.RaggedTensor.from_tensor(d['stu_mfcc'], padding=-1*tf.ones(80,))\n",
    "    start = tf.RaggedTensor.from_tensor(d['valid_stu_start'], padding=-1.)\n",
    "    duration = tf.RaggedTensor.from_tensor(d['valid_stu_duration'], padding=-1.)\n",
    "    ratio = 125\n",
    "    #Get_Gradient(value, start, duration, ratio)\n",
    "    # print(i)\n",
    "    # with tf.GradientTape() as t:\n",
    "    #     v2 = value * A\n",
    "    #     Final_Tensor = inform_pooling(batch, v2, start, duration, ratio)\n",
    "    #     J = tf.reduce_mean(Final_Tensor)\n",
    "    # print('Start Gradient')\n",
    "    # print(f'\\tLoss Value: {J}, \\n\\tOutput Shape {tf.shape(Final_Tensor)}')\n",
    "    # G = t.gradient(J,A)\n",
    "    # print(i,G)\n",
    "    # print('End Gradient\\n\\n')\n",
    "    # del t\n",
    "    # print(G)\n",
    "    if i ==30 :break\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d.keys()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class InformPooling(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_maps, ratios_list, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_maps = num_maps\n",
    "        self.ratios_list = ratios_list\n",
    "\n",
    "    @staticmethod\n",
    "    @tf.function\n",
    "    def inform_pooling(value, start, duration, ratio, eps=0.001):\n",
    "        batch = tf.shape(value)[0]\n",
    "        end = start + duration\n",
    "        start = tf.math.floor(start * ratio)\n",
    "        end = tf.math.ceil((end + eps) * ratio)\n",
    "        period = tf.cast(tf.stack([start, end], axis=-1), tf.int32)\n",
    "        tf.debugging.assert_less(period[..., 0], period[..., 1])\n",
    "        ret_b = tf.TensorArray(tf.float32, batch, infer_shape=False)\n",
    "        ret_count = tf.TensorArray(tf.int64, batch)\n",
    "        for batch_index in tf.range(batch):\n",
    "            value_l = value[batch_index]\n",
    "            val_ind_max = tf.shape(value_l)[0]\n",
    "            period_l = period[batch_index]\n",
    "            period_l_p = tf.math.minimum(period_l, val_ind_max - 1)\n",
    "            ret_count = ret_count.write(batch_index, tf.cast(tf.shape(period_l)[0], tf.int64))\n",
    "            indexes = tf.ragged.range(period_l_p[..., 0], period_l_p[..., 1])\n",
    "            value_indices = tf.gather(value_l, indexes)\n",
    "            pooled = tf.reduce_mean(value_indices, axis=1)\n",
    "            ret_b = ret_b.write(batch_index, pooled)\n",
    "        row_length = ret_count.stack()\n",
    "        ret = ret_b.concat()\n",
    "        return ret, row_length\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, value_list, start, duration):\n",
    "        # Iterate over both value_list and ratio_list\n",
    "        pooled_value = [self.inform_pooling(value, start, duration, ratio) for (value, ratio) in\n",
    "                        zip(value_list, self.ratios_list)]\n",
    "        ret = tf.concat([val for val, _ in pooled_value], axis=-1)\n",
    "        # Stupid way to shrink dynamic shape to static shape\n",
    "        return tf.RaggedTensor.from_row_lengths(ret, pooled_value[0][1])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "apl = InformPooling(3,[125 / 2**i for i in range(3)])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def getinfo(d,str_value, str_start, str_duration, str_words):\n",
    "    batch = 10\n",
    "    value = tf.RaggedTensor.from_tensor(d[str_value], padding=-1*tf.ones(80,))\n",
    "    start = tf.RaggedTensor.from_tensor(d[str_start], padding=-1.)\n",
    "    duration = tf.RaggedTensor.from_tensor(d[str_duration], padding=-1.)\n",
    "    ratio = 125\n",
    "    words = tf.RaggedTensor.from_tensor(d[str_words], padding=-1)\n",
    "    end = start + duration\n",
    "    period = tf.cast(tf.stack([start, end], axis=-1) * ratio, tf.int64)\n",
    "    return apl([value]*3, start, duration), words"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "v1, wo1 = getinfo(d,'stu_mfcc','valid_stu_start','valid_stu_duration', 'valid_ref_word')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d.keys()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "v2, wo2 = getinfo(d, 'ref_mfcc', 'valid_ref_start', 'valid_ref_duration', 'valid_ref_word')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.shape(v1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.shape(v2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@tf.function\n",
    "def compute_similarity(value_a,value_b, ref_a, ref_b, margin=0.25, eps=0.001):\n",
    "    #if ref_a equal ref_b then we consider it should be similar else it should be different,\n",
    "    #margin prevent it been push to far away\n",
    "    # compute the norm for ragged tensor\n",
    "    norm_of_a = tf.sqrt(tf.reduce_sum(tf.square(value_a),axis=-1, keepdims=True))\n",
    "    norm_of_b = tf.sqrt(tf.reduce_sum(tf.square(value_b),axis=-1, keepdims=True))\n",
    "    norm_a = value_a / (norm_of_a + eps)\n",
    "    norm_b = value_b / (norm_of_b + eps)\n",
    "    # compute cosine similarity for each sample in batch\n",
    "    # get batch size\n",
    "    batch_size = tf.shape(norm_a)[0]\n",
    "    loss_array = tf.TensorArray(tf.float32, batch_size, infer_shape=False)\n",
    "    for idx in tf.range(batch_size):\n",
    "        va = norm_a[idx]\n",
    "        vb = norm_b[idx]\n",
    "        ra = ref_a[idx]\n",
    "        rb = ref_b[idx]\n",
    "        similarity_matrix = tf.matmul(va,vb, transpose_b=True)\n",
    "        # compute the mask for the positive samples\n",
    "        mask = tf.cast(tf.equal(ra,rb),tf.float32)\n",
    "        # compute the mask for the negative samples\n",
    "        mask_neg = tf.cast(tf.not_equal(ra,rb),tf.float32)\n",
    "        # compute the number of positive and negative samples\n",
    "        num_pos = tf.cast(tf.reduce_sum(mask), tf.float32)\n",
    "        num_neg = tf.cast(tf.reduce_sum(mask_neg), tf.float32)\n",
    "        # compute the average similarity for the positive samples\n",
    "        # avoid 0\n",
    "        num_pos = tf.maximum(num_pos, 1.)\n",
    "        num_neg = tf.maximum(num_neg, 1.)\n",
    "        avg_sim_pos = tf.reduce_sum(tf.multiply(similarity_matrix,mask)) / num_pos\n",
    "        # compute the average similarity for the negative samples\n",
    "        avg_sim_neg = tf.reduce_sum(tf.multiply(similarity_matrix,mask_neg)) / num_neg\n",
    "        # compute the max similarity for the positive samples\n",
    "        max_sim_pos = tf.reduce_max(tf.multiply(similarity_matrix,mask))\n",
    "        # compute the min similarity for the negative samples\n",
    "        min_sim_neg = tf.reduce_min(tf.multiply(similarity_matrix,mask_neg))\n",
    "        # compute the average loss with margin\n",
    "        loss_avg = tf.maximum(0., margin + avg_sim_pos - avg_sim_neg)\n",
    "        # compute min_max loss with margin\n",
    "        loss_min_max = tf.maximum(0., margin + max_sim_pos - min_sim_neg)\n",
    "        # total loss\n",
    "        loss = loss_avg + loss_min_max\n",
    "        loss_array = loss_array.write(idx,loss)\n",
    "    total_loss = tf.reduce_sum(loss_array.stack())\n",
    "    return total_loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "compute_similarity(v1,v2,wo1,wo2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d['valid_ref_word']"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c = tf.matmul(v1,v2, transpose_b=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c.nested_row_lengths()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rt = tf.RaggedTensor.from_row_splits(\n",
    "    values=tf.RaggedTensor.from_row_splits(\n",
    "        values=[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
    "        row_splits=[0, 3, 3, 5, 9, 10]),\n",
    "    row_splits=[0, 1, 1, 5])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rt.nested_row_lengths()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ap = inform_pooling(value, start, duration, ratio)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.shape(ap)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.shape(tf.concat([ap,ap],axis=-1))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "down_sample_layer = tf.keras.layers.Conv1D(120,kernel_size=3,strides=2,padding=\"same\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "up_sample_layer = tf.keras.layers.Conv1DTranspose(120,kernel_size=4,strides=2,padding=\"same\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "i = d['stu_mfcc']"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s = down_sample_layer(i)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "u = up_sample_layer(s)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "u"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "i"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "u[:,:tf.shape(i)[2],:]"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.ensure_shape(i)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@tf.function\n",
    "def mt(i):\n",
    "    shape = tf.shape(i)[1]\n",
    "    s = down_sample_layer(i)\n",
    "    u = up_sample_layer(s)\n",
    "    cut = u[:,:shape]\n",
    "    return tf.concat([i,cut],axis=-1)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mt(i)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shape = tf.shape(i)[:-1]\n",
    "cut = tf.slice(u, tf.zeros_like(shape), shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rt = tf.RaggedTensor.from_uniform_row_length(\n",
    "    values=tf.RaggedTensor.from_row_splits(\n",
    "        values=[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
    "        row_splits=[0, 3, 5, 9, 10]),\n",
    "    uniform_row_length=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rt.nested_row_splits"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rt.row_splits"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rt.values"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rt"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dst, dse = ds.k_fold(10,1,32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exampl = next(iter(dst))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exampl.keys()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "d"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T01:44:40.479160Z",
     "start_time": "2023-10-20T01:44:40.468309Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
