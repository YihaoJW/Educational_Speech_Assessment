{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: [\"[Errno 2] The file to load file system plugin from does not exist.: '/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so'\"]\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: [\"dlopen(/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so, 0x0006): tried: '/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so' (no such file), '/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so' (no such file)\"]\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow import Tensor\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Callable, List, Tuple, Union, Optional, Dict, Any, Sequence, Iterable, TypeVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Disable all GPUS\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "visible_devices = tf.config.get_visible_devices()\n",
    "for device in visible_devices:\n",
    "    assert device.device_type != 'GPU'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class DataPipeFactory:\n",
    "    def __init__(self, tfrecord_path, ref_audio_path, word_information_path, cache=None):\n",
    "        self.tfrecord_path :Path = Path(tfrecord_path)\n",
    "        self.ref_audio_path :Path = Path(ref_audio_path)\n",
    "        self.word_information_path :Path = Path(word_information_path)\n",
    "        self.__cache_status = False\n",
    "        if not self.tfrecord_path.exists():\n",
    "            raise FileNotFoundError(f\"tfrecord_path {tfrecord_path} not found\")\n",
    "        if not self.ref_audio_path.exists():\n",
    "            raise FileNotFoundError(f\"ref_audio_path {ref_audio_path} not found\")\n",
    "        if not self.word_information_path.exists():\n",
    "            raise FileNotFoundError(f\"word_information_path {word_information_path} not found\")\n",
    "        self.__cache = str(cache)\n",
    "        self.__pairs : tf.int32 = 2\n",
    "        self.__available_voice = 4\n",
    "        self.__mel_bins = 80\n",
    "        self.__raw_data :tf.data.Dataset = self.__generate_raw_data()\n",
    "    #create the parser function to parse the serialized generated above\n",
    "    @staticmethod\n",
    "    def parse_function(serialized_example : tf.string) -> Dict[str, tf.Tensor]:\n",
    "        # Define a dict with the data-names and types we expect to find in the\n",
    "        # serialized example.\n",
    "        features = {\n",
    "            'RecordName': tf.io.FixedLenFeature([], tf.string),\n",
    "            'AudioSegment': tf.io.FixedLenFeature([], tf.string),\n",
    "            'SampleRate': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'Sentence': tf.io.FixedLenFeature([], tf.string),\n",
    "            'WordStart': tf.io.FixedLenFeature([], tf.string),\n",
    "            'WordDuration': tf.io.FixedLenFeature([], tf.string),\n",
    "            'MatchSegment': tf.io.FixedLenFeature([], tf.string),\n",
    "            'MatchReference': tf.io.FixedLenFeature([], tf.string),\n",
    "        }\n",
    "        # Parse the input tf.Example proto using the dictionary above.\n",
    "        e = tf.io.parse_single_example(serialized_example, features)\n",
    "        #Convert the serialized tensor to tensor\n",
    "        e['AudioSegment'] = tf.io.parse_tensor(e['AudioSegment'], out_type=tf.int16)\n",
    "        e['Sentence'] = tf.io.parse_tensor(e['Sentence'], out_type=tf.int64)\n",
    "        e['WordStart'] = tf.io.parse_tensor(e['WordStart'], out_type=tf.float32)\n",
    "        e['WordDuration'] = tf.io.parse_tensor(e['WordDuration'], out_type=tf.float32)\n",
    "        e['MatchSegment'] = tf.io.parse_tensor(e['MatchSegment'], out_type=tf.int64)\n",
    "        e['MatchReference'] = tf.io.parse_tensor(e['MatchReference'], out_type=tf.int64)\n",
    "        passage_id = tf.strings.split(e['RecordName'], sep='_')[3]\n",
    "        #convert tf.string to int\n",
    "        passage_id = tf.strings.to_number(passage_id, out_type=tf.int32) % 100000\n",
    "        #convert to tf.string\n",
    "        e['passage_id'] = tf.strings.as_string(passage_id)\n",
    "        return e\n",
    "\n",
    "    def __first_map_builder(self)-> Callable[[dict[str, Tensor]], dict[str, Tensor]]:\n",
    "        get_mfcc = self.get_mfcc\n",
    "        ref_audio_path = str(self.ref_audio_path.absolute())\n",
    "        word_information_path = str(self.word_information_path.absolute())\n",
    "        available_voice = self.__available_voice\n",
    "        def created_map(e: Dict[str, tf.Tensor]) -> Dict[str, tf.Tensor]:\n",
    "            a = {'stu_mfcc': get_mfcc(e['AudioSegment'], e['SampleRate'])}\n",
    "            ref_audio = tf.io.parse_tensor(tf.io.read_file(ref_audio_path + '/' + e['passage_id'] +'.tfs' ), out_type=tf.int16)\n",
    "            a['ref_mfcc'] = get_mfcc(ref_audio, e['SampleRate'])\n",
    "            passage_word = tf.io.parse_tensor(tf.io.read_file(word_information_path + '/' + e['passage_id'] +'_word.tfs' ), out_type=tf.int64)\n",
    "            reference_time =  tf.io.parse_tensor(tf.io.read_file(word_information_path + '/' + e['passage_id'] +'_ref.tfs' ), out_type=tf.float32)\n",
    "            a['valid_stu_start'] = tf.gather(e['WordStart'],e['MatchSegment'])\n",
    "            a['valid_stu_duration'] = tf.gather(e['WordDuration'],e['MatchSegment'])\n",
    "\n",
    "            a['valid_ref_word'] = tf.gather(passage_word, e['MatchReference'], batch_dims=1)\n",
    "            a['valid_ref_start'] = tf.gather(reference_time[..., 0], e['MatchReference'], batch_dims=1)\n",
    "            a['valid_ref_duration'] = tf.gather(reference_time[..., 1], e['MatchReference'], batch_dims=1)\n",
    "\n",
    "            a['RecordName'] = e['RecordName']\n",
    "            a['passage_id'] = e['passage_id']\n",
    "            a['MatchSegment'] = e['MatchSegment']\n",
    "            a['MatchReference'] = e['MatchReference']\n",
    "\n",
    "            a['stu_mfcc'].set_shape([None, 80])\n",
    "            a['ref_mfcc'].set_shape([available_voice, None, 80])\n",
    "            a['valid_stu_start'].set_shape([available_voice, None])\n",
    "            a['valid_stu_duration'].set_shape([available_voice, None])\n",
    "            a['valid_ref_word'].set_shape([available_voice, None])\n",
    "            a['valid_ref_start'].set_shape([available_voice, None])\n",
    "            a['valid_ref_duration'].set_shape([available_voice, None])\n",
    "            a['MatchSegment'].set_shape([available_voice, None])\n",
    "            a['MatchReference'].set_shape([available_voice, None])\n",
    "            return a\n",
    "        return created_map\n",
    "\n",
    "    def __generate_raw_data(self) -> tf.data.Dataset:\n",
    "        self.__raw_data = tf.data.TFRecordDataset(self.tfrecord_path, compression_type='GZIP')\\\n",
    "            .map(self.parse_function,  num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "            .map(self.__first_map_builder(), num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "        return self.__raw_data\n",
    "\n",
    "    @staticmethod\n",
    "    @tf.function\n",
    "    def get_mfcc(pcm: int,\n",
    "                 sample_rate: int = 16000,\n",
    "                 frame_length : int = 1024) -> tf.float32:\n",
    "        # Implement the mel-frequency coefficients (MFC) from a raw audio signal.\n",
    "        pcm = tf.cast(pcm, tf.float32) / tf.int16.max\n",
    "        st_fft = tf.signal.stft(pcm, frame_length=frame_length, frame_step=frame_length // 8, fft_length=frame_length)\n",
    "        spectrograms = tf.abs(st_fft)\n",
    "        # Warp the linear scale spectrograms into the mel-scale.\n",
    "        num_spectrogram_bins = frame_length // 2 + 1\n",
    "        lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, 80\n",
    "        linear_to_mel_weight_matrix =\\\n",
    "            tf.signal.linear_to_mel_weight_matrix(num_mel_bins, num_spectrogram_bins, sample_rate, lower_edge_hertz, upper_edge_hertz)\n",
    "        mel_spectrograms = tf.einsum('...t,tb->...b', spectrograms, linear_to_mel_weight_matrix)\n",
    "        log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "        return log_mel_spectrograms\n",
    "\n",
    "    @staticmethod\n",
    "    def __pair_mapping(main : dict[str, tf.Tensor], counter : dict[str, tf.Tensor]) -> dict[str, tf.Tensor]:\n",
    "        sample_dict = {}\n",
    "        random_ref_voice_id = tf.random.uniform(shape=[], minval=0, maxval=tf.shape(counter['ref_mfcc'])[0], dtype=tf.int32)\n",
    "        counter_random_ref_voice_id = tf.random.uniform(shape=[], minval=0, maxval=tf.shape(counter['ref_mfcc'])[0], dtype=tf.int32)\n",
    "        sample_dict['stu_mfcc'] = main['stu_mfcc']\n",
    "        sample_dict['ref_mfcc'] = main['ref_mfcc'][random_ref_voice_id]\n",
    "        sample_dict['valid_stu_start'] = main['valid_stu_start'][random_ref_voice_id]\n",
    "        sample_dict['valid_stu_duration'] = main['valid_stu_duration'][random_ref_voice_id]\n",
    "        sample_dict['valid_ref_word'] = main['valid_ref_word'][random_ref_voice_id]\n",
    "        sample_dict['valid_ref_start'] = main['valid_ref_start'][random_ref_voice_id]\n",
    "        sample_dict['valid_ref_duration'] = main['valid_ref_duration'][random_ref_voice_id]\n",
    "\n",
    "        sample_dict['counter_ref_mfcc'] = counter['ref_mfcc'][counter_random_ref_voice_id]\n",
    "\n",
    "        # Sample same mount of period from counter that match the main\n",
    "        # Get the range of word under main\n",
    "        main_word_range = tf.shape(sample_dict['valid_ref_word'])\n",
    "        # Sample same mount of period from counter that match the main\n",
    "        # Generate same amount of random integer match up the range of main_word_range\n",
    "        # counter_word_index = tf.random.uniform(shape=main_word_range, minval=0, maxval=tf.shape(counter['valid_ref_word'][counter_random_ref_voice_id])[0], dtype=tf.int32)\n",
    "        shuffled_index = tf.random.shuffle(tf.range(tf.shape(counter['valid_ref_word'][counter_random_ref_voice_id])[0]))\n",
    "        if tf.shape(shuffled_index)[0] > main_word_range[0]:\n",
    "            counter_word_index = shuffled_index[:main_word_range[0]]\n",
    "        else:\n",
    "            counter_word_index = tf.random.uniform(shape=main_word_range, minval=0, maxval=tf.shape(counter['valid_ref_word'][counter_random_ref_voice_id])[0], dtype=tf.int32)\n",
    "            # replace the value in the range of shuffled_index with the value in counter_word_index\n",
    "            counter_word_index = \\\n",
    "                tf.tensor_scatter_nd_update(\n",
    "                    counter_word_index,\n",
    "                    tf.range(tf.shape(shuffled_index)[0])[...,tf.newaxis],\n",
    "                    shuffled_index)\n",
    "        # Sample data using counter_word_index\n",
    "        sample_dict['counter_valid_ref_word'] = \\\n",
    "            tf.gather(counter['valid_ref_word'][counter_random_ref_voice_id], counter_word_index)\n",
    "        sample_dict['counter_valid_ref_start'] = \\\n",
    "            tf.gather(counter['valid_ref_start'][counter_random_ref_voice_id], counter_word_index)\n",
    "        sample_dict['counter_valid_ref_duration'] = \\\n",
    "            tf.gather(counter['valid_ref_duration'][counter_random_ref_voice_id], counter_word_index)\n",
    "        # determine if counter_valid_ref_word with main_valid_ref_word match up if match up return 1. else return -1.\n",
    "        sample_dict['counter_word_match'] = tf.where(tf.equal(sample_dict['counter_valid_ref_word'],\n",
    "                                                              sample_dict['valid_ref_word']), 1., -1.)\n",
    "        sample_dict['counter_pool_index'] = counter_word_index\n",
    "        return sample_dict\n",
    "\n",
    "    def pre_save(self) -> None:\n",
    "        self.__raw_data.save(self.__cache, compression='GZIP')\n",
    "        self.__cache_status = True\n",
    "        self.__raw_data = tf.data.Dataset.load(self.__cache).load(self.__cache)\n",
    "        print(f'Cache saved to {self.__cache}')\n",
    "\n",
    "    def get_raw_data(self) -> tf.data.Dataset:\n",
    "        if Path(self.__cache).exists() and not self.__cache_status:\n",
    "            self.__cache_status = True\n",
    "            print(f'Load cache from {self.__cache}')\n",
    "            self.__raw_data = tf.data.Dataset.load(self.__cache, compression='GZIP')\n",
    "        return self.__raw_data\n",
    "\n",
    "    def get_pair_data(self) -> tf.data.Dataset:\n",
    "        return self.get_raw_data().apply(self.__pair_map_handle(self.__pairs))\n",
    "\n",
    "    def __batching_handle(self, batch_size : int) -> Callable[[tf.data.Dataset], tf.data.Dataset]:\n",
    "        def handle(ds):\n",
    "            return ds\\\n",
    "                .padded_batch(batch_size,\n",
    "                              padding_values={k:tf.cast(-1, v.dtype) if v.dtype != tf.string else '' for k, v in ds.element_spec.items()})\\\n",
    "                .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        return handle\n",
    "\n",
    "    def __pair_map_handle(self, pairs : int,\n",
    "                          deterministic : bool = True)\\\n",
    "            -> Callable[[tf.data.Dataset], tf.data.Dataset]:\n",
    "        def handle(ds):\n",
    "            tuple_of_pairs = tuple(ds.shuffle(20, reshuffle_each_iteration=True) for _ in range(pairs))\n",
    "            comb_data = tf.data.Dataset.zip(tuple_of_pairs).filter(lambda x, y: x[\"RecordName\"] != y[\"RecordName\"])\n",
    "            return comb_data.map(self.__pair_mapping, num_parallel_calls=tf.data.AUTOTUNE,\n",
    "                                 deterministic=deterministic)\\\n",
    "                .shuffle(buffer_size=10, reshuffle_each_iteration=True)\n",
    "        return handle\n",
    "\n",
    "    def k_fold(self, total_fold : int,\n",
    "               fold_index : int,\n",
    "               batch_size : int,\n",
    "               deterministic :bool = False)\\\n",
    "            -> Tuple[tf.data.Dataset, tf.data.Dataset]:\n",
    "        if fold_index >= total_fold:\n",
    "            raise ValueError(\"fold_index must be less than total_fold\")\n",
    "        indexed_data = self.get_raw_data().enumerate()\n",
    "        train_data = indexed_data\\\n",
    "            .filter(lambda index, _: index % total_fold != fold_index)\\\n",
    "            .map(lambda _, data: data, num_parallel_calls=tf.data.AUTOTUNE, deterministic=deterministic)\\\n",
    "            .apply(self.__pair_map_handle(self.__pairs, deterministic=deterministic))\\\n",
    "            .apply(self.__batching_handle(batch_size))\n",
    "\n",
    "        test_data = indexed_data\\\n",
    "            .filter(lambda index, _: index % total_fold == fold_index)\\\n",
    "            .map(lambda _, data: data, num_parallel_calls=tf.data.AUTOTUNE, deterministic=deterministic)\\\n",
    "            .apply(self.__pair_map_handle(self.__pairs, deterministic=deterministic))\\\n",
    "            .apply(self.__batching_handle(batch_size))\n",
    "        return train_data, test_data\n",
    "\n",
    "    def get_batch_data(self,\n",
    "                       batch_size: int,\n",
    "                       deterministic = False) -> tf.data.Dataset:\n",
    "        return self.get_raw_data().apply(self.__pair_map_handle(self.__pairs, deterministic = deterministic)).apply(self.__batching_handle(batch_size))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#####\n",
    "#####"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load cache from ../DataFolder/cache/datapipe/cached\n"
     ]
    }
   ],
   "source": [
    "ds = DataPipeFactory('../DataFolder/Tensorflow_DataRecord/Student_Answer_Record.tfrecord',\n",
    "                     '../DataFolder/Siri_Related/Siri_Reference_Sample',\n",
    "                     '../DataFolder/Siri_Related/Siri_Dense_Index', cache='../DataFolder/cache/datapipe/cached')\n",
    "# dsp = ds.get_batch_data(10)\n",
    "# it = iter(dsp)\n",
    "ds.get_raw_data()\n",
    "A = tf.Variable(-1.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#ds.pre_save()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def inform_pooling(value, start, duration, ratio):\n",
    "    batch = tf.shape(value)[0]\n",
    "    end = start + duration\n",
    "    start = tf.math.floor(start * ratio)\n",
    "    end = tf.math.ceil((end + 0.001) * ratio)\n",
    "\n",
    "    period = tf.cast(tf.stack([start, end], axis=-1), tf.int32)\n",
    "    tf.debugging.assert_less(period[...,0], period[...,1])\n",
    "    ret_b = tf.TensorArray(tf.float32, batch, infer_shape=False)\n",
    "    ret_count = tf.TensorArray(tf.int32, batch)\n",
    "    for batch_index in tf.range(batch):\n",
    "        value_l = value[batch_index]\n",
    "        val_ind_max = tf.shape(value_l)[0]\n",
    "        period_l = period[batch_index]\n",
    "        period_l_p = tf.math.minimum(period_l, val_ind_max - 1)\n",
    "        ret_count = ret_count.write(batch_index, tf.shape(period_l)[0])\n",
    "        indexes = tf.ragged.range(period_l_p[..., 0], period_l_p[..., 1])\n",
    "        value_indices= tf.gather(value_l, indexes)\n",
    "        pooled = tf.reduce_mean(value_indices, axis=1)\n",
    "        ret_b = ret_b.write(batch_index, pooled)\n",
    "    row_length = ret_count.stack()\n",
    "    ret = ret_b.concat()\n",
    "    return tf.RaggedTensor.from_row_lengths(ret, row_length)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def Get_Gradient(value, start, duration, ratio):\n",
    "    with tf.GradientTape() as t:\n",
    "        v2 = value * A\n",
    "        Final_Tensor = inform_pooling(v2, start, duration, ratio)\n",
    "        J = tf.reduce_mean(Final_Tensor)\n",
    "        # tf.print(f'Losses: {J}, Output Shape: {tf.shape(Final_Tensor)}, Input Shape{tf.shape(v2)}')\n",
    "        G = t.gradient(J,[A])\n",
    "    return G"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "861097ad764648f4861016914e33f359"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 16:09:35.217810: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "for i,d in tqdm(enumerate(ds.get_batch_data(10))):\n",
    "    batch = 10\n",
    "    value = tf.RaggedTensor.from_tensor(d['stu_mfcc'], padding=-1*tf.ones(80,))\n",
    "    start = tf.RaggedTensor.from_tensor(d['valid_stu_start'], padding=-1.)\n",
    "    duration = tf.RaggedTensor.from_tensor(d['valid_stu_duration'], padding=-1.)\n",
    "    ratio = 125\n",
    "    Get_Gradient(value, start, duration, ratio)\n",
    "    # print(i)\n",
    "    # with tf.GradientTape() as t:\n",
    "    #     v2 = value * A\n",
    "    #     Final_Tensor = inform_pooling(batch, v2, start, duration, ratio)\n",
    "    #     J = tf.reduce_mean(Final_Tensor)\n",
    "    # print('Start Gradient')\n",
    "    # print(f'\\tLoss Value: {J}, \\n\\tOutput Shape {tf.shape(Final_Tensor)}')\n",
    "    # G = t.gradient(J,A)\n",
    "    # print(i,G)\n",
    "    # print('End Gradient\\n\\n')\n",
    "    # del t\n",
    "    # print(G)\n",
    "    # if i ==30 :break\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d['stu_mfcc'].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aa = tf.RaggedTensor.from_tensor(d['stu_mfcc'], padding=-1*tf.ones(80,))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shap = tf.shape(aa)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s2 = tf.experimental.DynamicRaggedShape.from_lengths(shap.static_lengths(True)[:-1] + [2,40])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shap.inner_shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.reshape(aa, s2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.RaggedTensor.from_tensor(d['valid_stu_start'], padding=-1.)[2]*125"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.RaggedTensor.from_tensor(d['valid_stu_duration'], padding=-1.)[2]*125"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A = tf.Variable(-1.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch = 10\n",
    "value = tf.RaggedTensor.from_tensor(d['stu_mfcc'], padding=-1*tf.ones(80,))\n",
    "start = tf.RaggedTensor.from_tensor(d['valid_stu_start'], padding=-1.)\n",
    "duration = tf.RaggedTensor.from_tensor(d['valid_stu_duration'], padding=-1.)\n",
    "ratio = 125\n",
    "end = start + duration\n",
    "period = tf.cast(tf.stack([start, end], axis=-1) * ratio, tf.int64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tf.GradientTape() as t:\n",
    "    v2 = value * A\n",
    "    Final_Tensor = inform_pooling(batch, v2, start, duration, ratio)\n",
    "    J = tf.reduce_mean(Final_Tensor)\n",
    "G = t.gradient(J,A)\n",
    "print(G)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.reduce_mean(Final_Tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Final_Tensor.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.shape(tf.ragged.stack([start,duration], axis=-1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rag = tf.ragged.range(period[..., 0][0], period[...,1][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g = tf.gather(value[0],rag)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.reduce_mean(g, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a,b = ds.k_fold(5, 0, 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dsr = ds.get_raw_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "next(iter(dsr.shuffle(5).window(2)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###\n",
    "#\n",
    "# main_word_range = tf.range(tf.shape(i[0]['valid_ref_word'])[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Path(str(None))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(30)\n",
    "window_size = 5\n",
    "key_func = lambda x: x%3\n",
    "reduce_func = lambda key, dataset: dataset.batch(window_size)\n",
    "dataset = dataset.group_by_window(\n",
    "    key_func=key_func,\n",
    "    reduce_func=reduce_func,\n",
    "    window_size=window_size)\n",
    "for elem in dataset.as_numpy_iterator():\n",
    "    print(elem)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
