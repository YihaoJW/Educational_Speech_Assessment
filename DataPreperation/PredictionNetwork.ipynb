{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-09T18:51:07.138175Z",
     "start_time": "2023-06-09T18:51:05.156668Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: [\"[Errno 2] The file to load file system plugin from does not exist.: '/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so'\"]\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: [\"dlopen(/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so, 0x0006): tried: '/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so' (no such file), '/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so' (no such file)\"]\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "/Users/jackwang/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow import Tensor\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Callable, List, Tuple, Union, Optional, Dict, Any, Sequence, Iterable, TypeVar\n",
    "from DataPipe import DataPipeFactory\n",
    "from util_function import inform_pooling, Get_Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Disable all GPUS\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "visible_devices = tf.config.get_visible_devices()\n",
    "for device in visible_devices:\n",
    "    assert device.device_type != 'GPU'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T18:51:08.047892Z",
     "start_time": "2023-06-09T18:51:08.045088Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#####\n",
    "#####6824149711"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T18:51:08.751368Z",
     "start_time": "2023-06-09T18:51:08.749415Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "ds = DataPipeFactory('../DataFolder/Tensorflow_DataRecord/Student_Answer_Record.tfrecord',\n",
    "                     '../DataFolder/Siri_Related/Siri_Reference_Sample',\n",
    "                     '../DataFolder/Siri_Related/Siri_Dense_Index', cache='../DataFolder/cache/datapipe/cached')\n",
    "# dsp = ds.get_batch_data(10)\n",
    "# it = iter(dsp)\n",
    "ds.get_raw_data()\n",
    "A = tf.Variable(-1.)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T18:51:09.888248Z",
     "start_time": "2023-06-09T18:51:09.586372Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#ds.pre_save()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T18:51:10.656092Z",
     "start_time": "2023-06-09T18:51:10.653222Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.data.ops.iterator_ops.OwnedIterator at 0x2c0bb9730>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(ds.get_batch_data(10, interleave=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T18:51:11.205510Z",
     "start_time": "2023-06-09T18:51:11.065470Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "928cdbd715ba488db0593a6b61f1b701"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 13:51:13.686815: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-06-09 13:51:14.340295: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INVALID_ARGUMENT: Detected unsupported operations when trying to compile graph __inference___single_mapping_754[] on XLA_CPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_CPU_JIT devices compatible with node {{node main_7}}\n",
      "\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[]], _user_specified_name=\"main\", index=2){{node main_7}}\n",
      "2023-06-09 13:51:14.696891: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INVALID_ARGUMENT: Detected unsupported operations when trying to compile graph __inference___single_mapping_754[] on XLA_CPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_CPU_JIT devices compatible with node {{node main_7}}\n",
      "\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[]], _user_specified_name=\"main\", index=2){{node main_7}}\n",
      "2023-06-09 13:51:14.697588: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INVALID_ARGUMENT: Detected unsupported operations when trying to compile graph __inference___single_mapping_754[] on XLA_CPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_CPU_JIT devices compatible with node {{node main_7}}\n",
      "\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[]], _user_specified_name=\"main\", index=2){{node main_7}}\n",
      "2023-06-09 13:51:14.845049: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INVALID_ARGUMENT: Detected unsupported operations when trying to compile graph __inference___single_mapping_754[] on XLA_CPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_CPU_JIT devices compatible with node {{node main_7}}\n",
      "\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[]], _user_specified_name=\"main\", index=2){{node main_7}}\n",
      "2023-06-09 13:51:14.848031: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INVALID_ARGUMENT: Detected unsupported operations when trying to compile graph __inference___single_mapping_754[] on XLA_CPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_CPU_JIT devices compatible with node {{node main_7}}\n",
      "\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[]], _user_specified_name=\"main\", index=2){{node main_7}}\n",
      "2023-06-09 13:51:14.889568: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INVALID_ARGUMENT: Detected unsupported operations when trying to compile graph __inference___single_mapping_754[] on XLA_CPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_CPU_JIT devices compatible with node {{node main_7}}\n",
      "\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[]], _user_specified_name=\"main\", index=2){{node main_7}}\n",
      "2023-06-09 13:51:14.892961: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INVALID_ARGUMENT: Detected unsupported operations when trying to compile graph __inference___single_mapping_754[] on XLA_CPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_CPU_JIT devices compatible with node {{node main_7}}\n",
      "\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[]], _user_specified_name=\"main\", index=2){{node main_7}}\n",
      "2023-06-09 13:51:15.088445: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INVALID_ARGUMENT: Detected unsupported operations when trying to compile graph __inference___single_mapping_754[] on XLA_CPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_CPU_JIT devices compatible with node {{node main_7}}\n",
      "\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[]], _user_specified_name=\"main\", index=2){{node main_7}}\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_7_device_/job:localhost/replica:0/task:0/device:CPU:0}} Detected unsupported operations when trying to compile graph __inference___single_mapping_754[] on XLA_CPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_CPU_JIT devices compatible with node {{node main_7}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[]], _user_specified_name=\"main\", index=2){{node main_7}}\n\t [[StatefulPartitionedCall]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i,d \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28menumerate\u001B[39m(ds\u001B[38;5;241m.\u001B[39mget_batch_data(\u001B[38;5;241m10\u001B[39m, interleave\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, deterministic\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m))):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m50\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m      3\u001B[0m         \u001B[38;5;28mprint\u001B[39m(i)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tqdm/notebook.py:259\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    257\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m     it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(tqdm_notebook, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[0;32m--> 259\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m    262\u001B[0m \u001B[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tqdm/std.py:1195\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1192\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1195\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1196\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1197\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1198\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:797\u001B[0m, in \u001B[0;36mOwnedIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    796\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 797\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    798\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOutOfRangeError:\n\u001B[1;32m    799\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:780\u001B[0m, in \u001B[0;36mOwnedIterator._next_internal\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    777\u001B[0m \u001B[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001B[39;00m\n\u001B[1;32m    778\u001B[0m \u001B[38;5;66;03m# to communicate that there is no more data to iterate over.\u001B[39;00m\n\u001B[1;32m    779\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecution_mode(context\u001B[38;5;241m.\u001B[39mSYNC):\n\u001B[0;32m--> 780\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterator_get_next\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    781\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    782\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    783\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_shapes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    785\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    786\u001B[0m     \u001B[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001B[39;00m\n\u001B[1;32m    787\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_element_spec\u001B[38;5;241m.\u001B[39m_from_compatible_tensor_list(ret)  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3016\u001B[0m, in \u001B[0;36miterator_get_next\u001B[0;34m(iterator, output_types, output_shapes, name)\u001B[0m\n\u001B[1;32m   3014\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[1;32m   3015\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 3016\u001B[0m   \u001B[43m_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from_not_ok_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3017\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_FallbackException:\n\u001B[1;32m   3018\u001B[0m   \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Code-_CZGGnvj/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7262\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   7260\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name):\n\u001B[1;32m   7261\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 7262\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: {{function_node __wrapped__IteratorGetNext_output_types_7_device_/job:localhost/replica:0/task:0/device:CPU:0}} Detected unsupported operations when trying to compile graph __inference___single_mapping_754[] on XLA_CPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_CPU_JIT devices compatible with node {{node main_7}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[]], _user_specified_name=\"main\", index=2){{node main_7}}\n\t [[StatefulPartitionedCall]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "for i,d in tqdm(enumerate(ds.get_batch_data(10, interleave=False, deterministic=False))):\n",
    "    if i % 50 == 0:\n",
    "        print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T18:51:15.332791Z",
     "start_time": "2023-06-09T18:51:13.586977Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i,d in tqdm(enumerate(ds.get_batch_data(10))):\n",
    "    batch = 10\n",
    "    value = tf.RaggedTensor.from_tensor(d['stu_mfcc'], padding=-1*tf.ones(80,))\n",
    "    start = tf.RaggedTensor.from_tensor(d['valid_stu_start'], padding=-1.)\n",
    "    duration = tf.RaggedTensor.from_tensor(d['valid_stu_duration'], padding=-1.)\n",
    "    ratio = 125\n",
    "    #Get_Gradient(value, start, duration, ratio)\n",
    "    # print(i)\n",
    "    # with tf.GradientTape() as t:\n",
    "    #     v2 = value * A\n",
    "    #     Final_Tensor = inform_pooling(batch, v2, start, duration, ratio)\n",
    "    #     J = tf.reduce_mean(Final_Tensor)\n",
    "    # print('Start Gradient')\n",
    "    # print(f'\\tLoss Value: {J}, \\n\\tOutput Shape {tf.shape(Final_Tensor)}')\n",
    "    # G = t.gradient(J,A)\n",
    "    # print(i,G)\n",
    "    # print('End Gradient\\n\\n')\n",
    "    # del t\n",
    "    # print(G)\n",
    "    if i ==30 :break\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class InformPooling(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_maps, ratios_list, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_maps = num_maps\n",
    "        self.ratios_list = ratios_list\n",
    "\n",
    "    @staticmethod\n",
    "    @tf.function\n",
    "    def inform_pooling(value, start, duration, ratio, eps=0.001):\n",
    "        batch = tf.shape(value)[0]\n",
    "        end = start + duration\n",
    "        start = tf.math.floor(start * ratio)\n",
    "        end = tf.math.ceil((end + eps) * ratio)\n",
    "        period = tf.cast(tf.stack([start, end], axis=-1), tf.int32)\n",
    "        tf.debugging.assert_less(period[..., 0], period[..., 1])\n",
    "        ret_b = tf.TensorArray(tf.float32, batch, infer_shape=False)\n",
    "        ret_count = tf.TensorArray(tf.int64, batch)\n",
    "        for batch_index in tf.range(batch):\n",
    "            value_l = value[batch_index]\n",
    "            val_ind_max = tf.shape(value_l)[0]\n",
    "            period_l = period[batch_index]\n",
    "            period_l_p = tf.math.minimum(period_l, val_ind_max - 1)\n",
    "            ret_count = ret_count.write(batch_index, tf.cast(tf.shape(period_l)[0], tf.int64))\n",
    "            indexes = tf.ragged.range(period_l_p[..., 0], period_l_p[..., 1])\n",
    "            value_indices = tf.gather(value_l, indexes)\n",
    "            pooled = tf.reduce_mean(value_indices, axis=1)\n",
    "            ret_b = ret_b.write(batch_index, pooled)\n",
    "        row_length = ret_count.stack()\n",
    "        ret = ret_b.concat()\n",
    "        return ret, row_length\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, value_list, start, duration):\n",
    "        # Iterate over both value_list and ratio_list\n",
    "        pooled_value = [self.inform_pooling(value, start, duration, ratio) for (value, ratio) in\n",
    "                        zip(value_list, self.ratios_list)]\n",
    "        ret = tf.concat([val for val, _ in pooled_value], axis=-1)\n",
    "        # Stupid way to shrink dynamic shape to static shape\n",
    "        return tf.RaggedTensor.from_row_lengths(ret, pooled_value[0][1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "apl = InformPooling(3,[125 / 2**i for i in range(3)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getinfo(d,str_value, str_start, str_duration, str_words):\n",
    "    batch = 10\n",
    "    value = tf.RaggedTensor.from_tensor(d[str_value], padding=-1*tf.ones(80,))\n",
    "    start = tf.RaggedTensor.from_tensor(d[str_start], padding=-1.)\n",
    "    duration = tf.RaggedTensor.from_tensor(d[str_duration], padding=-1.)\n",
    "    ratio = 125\n",
    "    words = tf.RaggedTensor.from_tensor(d[str_words], padding=-1)\n",
    "    end = start + duration\n",
    "    period = tf.cast(tf.stack([start, end], axis=-1) * ratio, tf.int64)\n",
    "    return apl([value]*3, start, duration), words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "v1, wo1 = getinfo(d,'stu_mfcc','valid_stu_start','valid_stu_duration', 'valid_ref_word')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "v2, wo2 = getinfo(d, 'ref_mfcc', 'valid_ref_start', 'valid_ref_duration', 'valid_ref_word')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.shape(v1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.shape(v2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_similarity(value_a,value_b, ref_a, ref_b, margin=0.25, eps=0.001):\n",
    "    #if ref_a equal ref_b then we consider it should be similar else it should be different,\n",
    "    #margin prevent it been push to far away\n",
    "    # compute the norm for ragged tensor\n",
    "    norm_of_a = tf.sqrt(tf.reduce_sum(tf.square(value_a),axis=-1, keepdims=True))\n",
    "    norm_of_b = tf.sqrt(tf.reduce_sum(tf.square(value_b),axis=-1, keepdims=True))\n",
    "    norm_a = value_a / (norm_of_a + eps)\n",
    "    norm_b = value_b / (norm_of_b + eps)\n",
    "    # compute cosine similarity for each sample in batch\n",
    "    # get batch size\n",
    "    batch_size = tf.shape(norm_a)[0]\n",
    "    loss_array = tf.TensorArray(tf.float32, batch_size, infer_shape=False)\n",
    "    for idx in tf.range(batch_size):\n",
    "        va = norm_a[idx]\n",
    "        vb = norm_b[idx]\n",
    "        ra = ref_a[idx]\n",
    "        rb = ref_b[idx]\n",
    "        similarity_matrix = tf.matmul(va,vb, transpose_b=True)\n",
    "        # compute the mask for the positive samples\n",
    "        mask = tf.cast(tf.equal(ra,rb),tf.float32)\n",
    "        # compute the mask for the negative samples\n",
    "        mask_neg = tf.cast(tf.not_equal(ra,rb),tf.float32)\n",
    "        # compute the number of positive and negative samples\n",
    "        num_pos = tf.cast(tf.reduce_sum(mask), tf.float32)\n",
    "        num_neg = tf.cast(tf.reduce_sum(mask_neg), tf.float32)\n",
    "        # compute the average similarity for the positive samples\n",
    "        # avoid 0\n",
    "        num_pos = tf.maximum(num_pos, 1.)\n",
    "        num_neg = tf.maximum(num_neg, 1.)\n",
    "        avg_sim_pos = tf.reduce_sum(tf.multiply(similarity_matrix,mask)) / num_pos\n",
    "        # compute the average similarity for the negative samples\n",
    "        avg_sim_neg = tf.reduce_sum(tf.multiply(similarity_matrix,mask_neg)) / num_neg\n",
    "        # compute the max similarity for the positive samples\n",
    "        max_sim_pos = tf.reduce_max(tf.multiply(similarity_matrix,mask))\n",
    "        # compute the min similarity for the negative samples\n",
    "        min_sim_neg = tf.reduce_min(tf.multiply(similarity_matrix,mask_neg))\n",
    "        # compute the average loss with margin\n",
    "        loss_avg = tf.maximum(0., margin + avg_sim_pos - avg_sim_neg)\n",
    "        # compute min_max loss with margin\n",
    "        loss_min_max = tf.maximum(0., margin + max_sim_pos - min_sim_neg)\n",
    "        # total loss\n",
    "        loss = loss_avg + loss_min_max\n",
    "        loss_array = loss_array.write(idx,loss)\n",
    "    total_loss = tf.reduce_sum(loss_array.stack())\n",
    "    return total_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compute_similarity(v1,v2,wo1,wo2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d['valid_ref_word']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c = tf.matmul(v1,v2, transpose_b=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c.nested_row_lengths()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rt = tf.RaggedTensor.from_row_splits(\n",
    "    values=tf.RaggedTensor.from_row_splits(\n",
    "        values=[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
    "        row_splits=[0, 3, 3, 5, 9, 10]),\n",
    "    row_splits=[0, 1, 1, 5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rt.nested_row_lengths()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ap = inform_pooling(value, start, duration, ratio)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.shape(ap)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.shape(tf.concat([ap,ap],axis=-1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "down_sample_layer = tf.keras.layers.Conv1D(120,kernel_size=3,strides=2,padding=\"same\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "up_sample_layer = tf.keras.layers.Conv1DTranspose(120,kernel_size=4,strides=2,padding=\"same\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = d['stu_mfcc']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s = down_sample_layer(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "u = up_sample_layer(s)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "u"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "u[:,:tf.shape(i)[2],:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.ensure_shape(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def mt(i):\n",
    "    shape = tf.shape(i)[1]\n",
    "    s = down_sample_layer(i)\n",
    "    u = up_sample_layer(s)\n",
    "    cut = u[:,:shape]\n",
    "    return tf.concat([i,cut],axis=-1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mt(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shape = tf.shape(i)[:-1]\n",
    "cut = tf.slice(u, tf.zeros_like(shape), shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rt = tf.RaggedTensor.from_uniform_row_length(\n",
    "    values=tf.RaggedTensor.from_row_splits(\n",
    "        values=[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
    "        row_splits=[0, 3, 5, 9, 10]),\n",
    "    uniform_row_length=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rt.nested_row_splits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rt.row_splits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rt.values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dst, dse = ds.k_fold(10,1,32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exampl = next(iter(dst))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exampl.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
