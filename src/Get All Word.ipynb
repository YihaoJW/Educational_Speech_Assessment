{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem import LancasterStemmer\n",
    "import dill"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DataFolder/Original_CSV/yrs12_passages.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "passage = df['passage'].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "unique_word = set()\n",
    "stem = LancasterStemmer()\n",
    "for e in passage:\n",
    "    #match all word using regex and add to set\n",
    "    word_ls = list(map(lambda x: stem.stem(x), re.findall(r'\\w+', e.lower())))\n",
    "    unique_word.update(word_ls)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#Using dill to save the set\n",
    "with open('unique_word.dill', 'wb') as f:\n",
    "    dill.dump(unique_word, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "1674"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_word)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TF2 version\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "m = hub.KerasLayer('https://tfhub.dev/google/trillsson5/1')\n",
    "# NOTE: Audio should be floats in [-1, 1], sampled at 16kHz. Model input is of\n",
    "# the shape [batch size, time]."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "audio_samples = tf.random.normal([3, 64000])\n",
    "embeddings = m(audio_samples)['embedding']\n",
    "# Models internally aggregate over time. For a time-series of embeddings, the\n",
    "# user can frame audio however they want.\n",
    "embeddings.shape.assert_is_compatible_with([None, 1024])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3, 1024), dtype=float32, numpy=\narray([[-1.5436294 ,  0.3506941 , -0.48050883, ...,  2.8203986 ,\n        -0.82041126, -1.9124141 ],\n       [-1.5482461 ,  0.3428351 , -0.4758531 , ...,  2.824588  ,\n        -0.83504   , -1.9144915 ],\n       [-1.5582081 ,  0.3560771 , -0.48131317, ...,  2.794648  ,\n        -0.83085126, -1.917218  ]], dtype=float32)>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3, 1024), dtype=float32, numpy=\narray([[-1.1291425 ,  0.4191693 ,  0.87145674, ...,  0.97673386,\n        -1.1060619 , -1.4092574 ],\n       [-1.1275656 ,  0.44298258,  0.8755819 , ...,  0.92630476,\n        -1.0676109 , -1.4421777 ],\n       [-1.1662369 ,  0.46046028,  0.8969983 , ...,  0.9104195 ,\n        -1.083088  , -1.4256439 ]], dtype=float32)>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "model = hub.KerasLayer(\"https://tfhub.dev/vasudevgupta7/wav2vec2-960h/1\")\n",
    "# For using this model, it's important to set `jit_compile=True` on GPUs/CPUs\n",
    "# as some operations in this model (i.e. group-convolutions) are unsupported without it\n",
    "model = tf.function(model, jit_compile=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
